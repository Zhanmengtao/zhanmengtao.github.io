{"pages":[{"title":"about","text":"关于我个人介绍云南民族大学民族医药学院硕士研究生，目前在学习生物信息学。 学习方向生物信息学 联系方式欢迎在评论区留下有建设性的评论点击右下角通过 DaoVoice 联系我常用邮箱：1406390902@qq.com 关于本博客这个博客大概诞生于2019年9月，在经历了 CSDN 和博客园之后，我发现了这个方便又具有一定扩展性的博客引擎，并琢磨于各种模板，最终选择了 Next。 我在其他平台也写过文章，得到过一定的关注，不过，无奈的广告、不相关的推荐，总是充斥着作者和读者的眼球。 终是有一种寄人篱下的感觉。所以我决定搭建个人博客，这也是我学习路上的“印记”。 旅途愉快。 次は现実世界で会おう。 そしたらまた、同じように友だちになれるよ。 下次在现实中见面吧。 到那个时候，我们还能再次成为朋友。","link":"/about/index.html"},{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"读书 | 文献 | 软件","text":"2019 年 读书（9） 《围城》(2.4) 突然很怕自己像方鸿渐一样，凭借着一点小聪明混到留洋博士，却没能踏实地学习知识，而是与鲍小姐之辈虚度青春；不喜欢爱自己的苏文纨，却爱上了不喜欢自己唐晓芙；与曾经的情敌赵辛楣成为挚友；受不了充满尔虞我诈的三闾大学，与略显平凡的孙柔嘉结婚，又因双方家庭等原因一怒之下分手。 最后想起饭局上的那句“爱情就像是一座围城，里面的人想出来，外面的人想进去”。 《我所有的朋友都死了》(2.5) 理解不了哪里治愈了 《1988：我想和这个世界谈谈》(4.6) 实验室停电，一口气看完了韩寒这部小说。其实我对书中的部分文字游戏不是很感冒，甚至读到1/3想给它差评，不过一句话让我有了改观，“工作时候我离开了所有我熟悉的环境和朋友，这个世界之大能让你完全把自己洗没了，在一个陌生的环境里，我可以重新塑造一遍我自己，没有什么是不会改变的，我上一个角色已经演完了，这是我接的新戏。” 这其实与我坚持去外省读大学的一个原因不谋而合，所以我想书中很多观点还是有道理的，只是我从没想过这样疯狂的经历，也没对生活的定义有什么思考。 刚去知乎翻了一圈书评，是我太年轻思想太简单，虽然知道有隐喻，没想到隐喻得这么巧妙。第一次看韩寒的书，文风和格局确实与张嘉佳郭敬明之类差了不止一个档次，最近会多看几部。 《三十而立》(4.7) 李健是我非常喜欢的一个艺人，在我看来，他参加综艺聊天时比唱歌更具有魅力，没有夸张强调自己的学历，但他的话语中会很自然的流露出幽默高贵的灵魂。 初读王小波的小说给我的就是这种感觉，不过要强烈百倍千倍。这好像不是一本小说，而是一个非常有学识的男人坐在椅子上，为你讲述一个疯狂少年的故事，话语中满是幽默和思辨。简简单单的小事，不需要什么华丽的辞藻，却听上几个小时也不会觉得无聊。 《黄金时代》(4.15) 我很早就听过这本书，对它期望值很高。前半部一直以读小黄书的心态看完，到他们俩被斗争，才开始思考起来。陈清扬丈夫进了监狱（看样子不会出来了），追逐自己喜欢的伟大友谊，却被旧思想拘束；可破鞋这种东西就算是在当代社会也要受到鄙视，又不能完全将她受到的迫害归结于那个年代。所以我很不理解这本小说到底想表达什么，是对封建制度的讽刺？对无拘无束的向往？还是对人生的某种形容？看影评去了。 一本正经开车只服王小波。“我过二十一岁生日那天，打算在晚上引诱陈清扬，因为陈清扬是我的朋友，而且胸部很丰满，腰很细，屁股浑圆。除此之外，她的脖子端正修长，脸也很漂亮。我想和她性交，而且认为她不应该不同意，假如她想借我的身体练开膛，我准让她开；所以我借她身体一用也没什么不可以。唯一的问题是她是个女人，女人家总有点小器。为此我要启发她，所以我开始阐明什么叫作义气。” 《漫画算法：小灰的算法之旅》(5.4) 书虽然有200多页不过图很多，大概三个小时就翻了一遍，比较适合没有太多算法基础的人拿来入门。前面讲数据结构基础和排序算法比较无聊，毕竟这部分已经有太多经典的书籍了，唯一不同的就是用漫画当噱头。第五章第六章讲面试题和实际应用还比较有意思，有的算法确实想不到最优解。 其实我觉得可以去除掉基础部分，不过受众人群想必会少很多。 《图解HTTP》(5.19) 讲解了 HTTP 协议的一些基础知识，适合刚入门的新手，对于系统学习过 web 方面知识的人来说显得简单，大概起个查缺补漏、丰富知识体系的作用。 HTTP 首部字段和 web 安全方面的讲解略显无聊。 《红手指》(5.30) 书评中很多人开着上帝视角吐槽昭夫和八重子，但设想一下，如果你某一天下班回家发现自己的孩子杀了人，真的可以做出最正确的选择吗？说实话，我无法写下一个笃定的答案，或者说，“比起思索该如何应对，我更愿意去祈祷那种事不要发生”。 《镖人》(1-5)(6.7) 观影（9） 《太空旅客》 (1.17) 吹爆大表姐！ 《无名之辈》 (1.21) 《我不是药神》(1.23) 《羞羞的铁拳》(1.25) 《狗十三》(1.25) 《密室逃生 Escape Room》(1.28) 真的是情节环环相扣，从第一个密室开始一口气都不敢松。 《疯狂的外星人》(2.7) 《复仇者联盟4：终局之战》(5.1) 我最爱的钢铁侠和寡姐死了，好在奇异博士回来了。 《蝴蝶效应3：启示》 追番（8） 《我的英雄学院》第一季（1.1） 《我的英雄学院》第二季（1.6） 绿谷 vs 轰酱那场也太燃了吧 《我的英雄学院》第三季（1.22） 《刀剑神域》第一季 (2.8) 《一拳超人》第一季 (3.15) 《镇魂街》第一季 (4.26) 《刺客伍六七》(4.27) 《鬼灭之刃》(6.4)","link":"/reading/index.html"}],"posts":[{"title":"De novo 基因组 GO 注释小窗口","text":"目前对于GO功能注释的思路有 以下常见的三种： BLAST+InterProScan =&gt; omicsbox可以先通过使用 blastp 进行nr注释，那么问题就来了，nr 数据库截至2018年12月已经有120G左右的数据量了，根据我的个人使用经验，对25000条蛋白进行32线程的并行化比对，差不多要半个月左右。很显然，在计算资源有限的条件下这是不现实的，那么大概就会出现两种思路： 缩小数据库：一种是使用Swiss-Prot等小的数据库进行注释；另一种就是根据基于taxid构建 nr子数据库了，具体的构建可见 基于taxid构建Blast database_bioinfomatics2medicine_新浪博客 diamond: Accelerated BLAST compatible local sequence aligner.其主页介绍如下： DIAMOND is a sequence aligner for protein and translated DNA searches, designed for high performance analysis of big sequence data. The key features are: Pairwise alignment of proteins and translated DNA at 500x-20,000x speed of BLAST. Frameshift alignments for long read analysis. Low resource requirements and suitable for running on standard desktops or laptops. Various output formats, including BLAST pairwise, tabular and XML, as well as taxonomic classification. 它就是那么快，相对于 blastp 的半个月，在 ‘–more-sensitive’ 模式下也仅需要4-5个小时。 在nr注释完之后,就到使用 omicsbox mapping GO id 了。omicsbox 所有版本均需要购买，但价格比以前（Blast2GO）便宜很多。当然如果条件不允许，那么不如就来个本地化吧。 diamond 及 Blast2go 的联用blast2go本地化陈连福 centos6.9 代码： installing Blast2go Databases 1234567891011mkdir /opt/biosoft/blast2gocd /opt/biosoft/blast2gowget http://archive.geneontology.org/latest-full/go_monthly-assocdb-data.gzascp -k 1 -T -l 200M -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh --host=ftp-private.ncbi.nlm.nih.gov --user=anonftp --mode=recv /gene/DATA/gene_info.gz 。/ascp -k 1 -T -l 200M -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh --host=ftp-private.ncbi.nlm.nih.gov --user=anonftp --mode=recv /gene/DATA/gene2accession.gz ./wget ftp://ftp.pir.georgetown.edu/databases/idmapping/idmapping.tb.gz 注：对于不能使用aspera加速下载的文件可以试试 lftp -e ‘pget -n NUM -c url; exit’实行多线程下载 123456789101112131415gzip -dv go_monthly-assocdb-data.gzgzip -dv gene_info.gzgzip -dv gene2accession.gzgzip -dv idmapping.tb.gztar zxf ~/software/local_b2g_db.tar.gzmv local_b2g_db/* ./ &amp;&amp; rm -rf local_b2g_db/perl -p -i -e 's/go_201512-assocdb-data/go_2017-assocdb-data/' install_blast2goDB.sh./install_blast2goDB.sh 下载NR 数据库到自己的Blast+ db 中12345wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.2.28/ncbi-blast-2.2.28+-x64-linux.tar.gztar -zxf ncbi-blast-2.2.28+-x64-linux.tar.gz -C /opt/biosoft//opt/biosoft/ncbi-blast-2.2.28+/bin/blastdbcmd -db nr -entry all -out nr.faa 值得注意的是这里我用的blastdbcmd是ncbi-blast-2.2.28+的，输出的 nr.faa 文件中序列名是 “&gt;gi|66816243|ref|XP_642131.1| hypothetical protein DDB_G0277827” ，但如果用的是 ncbi-blast-2.6.0+的 blastdbcmd，输出没有GI号，原因可能是：As of September 2016, the integer sequence identifiers known as “GIs” will no longer be included in the GenBank, GenPept, and FASTA formats supported by NCBI for the display of sequence records.In addition, the FASTA format will no longer include the database source abbreviation. Please refer to the NCBI News Announcement posting for more detail. 1wget https://github.com/bbuchfink/diamond/releases/download/v0.9.24/diamond-linux64.tar.gz 注：如果在将diamond输出的XML文件导入到 b2g4pipe_v2.5 中出现 “Annotation of 0 seqs with 0 annots finished. Now searching for orfan IPRs…” 这个issues，那可能你的diamond版本有点旧了。 12345678910111213141516171819202122232425tar -zxf diamond-linux64.tar.gzmv diamond ~/bin/cp ../interpro/proteins.fasta ./ascp -k 1 -T -l 200M -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh --host=ftp-private.ncbi.nlm.nih.gov --user=anonftp --mode=recv /pub/taxonomy/accession2taxid/prot.accession2taxid.gz ./prot.accession2taxid.gzascp -k 1 -T -l 200M -i ~/.aspera/connect/etc/asperaweb_id_dsa.openssh --host=ftp-private.ncbi.nlm.nih.gov --user=anonftp --mode=recv /pub/taxonomy/taxdmp.zip ./unzip taxdmp.zip/opt/biosoft/ncbi-blast-2.2.28+/bin/blastdbcmd -db nr -entry all -out nr.faadiamond makedb --in nr.faa -d nr --taxonmap prot.accession2taxid.gz --taxonnodes nodes.dmp #### DIAMOND v0.9.24diamond blastp --query proteins.fasta --more-sensitive --db nr --evalue 1e-5 --salltitles --threads 64 --outfmt 5 --out nr.xmlperl -p -e 's/diamond 0.9.24/BLASTP 2.2.26/' nr.xml &gt; nr_new.xmlperl -p -i -e 's/^Dbacces.dbname=.*/Dbacces.dbname=b2gdb/' b2gPipe.propertiesperl -p -i -e 's/^Dbacces.dbhost=.*/Dbacces.dbhost=127.0.0.1/' b2gPipe.propertiesjava -cp *:ext/*: es.blast2go.prog.B2GAnnotPipe -in ../nr_new.xml -out go -annot -dat -annex 整合InterProScan的结果可以使用下面的脚本merge_interpro_to_go.pl b2g4pipe/go.annot ../interpro/interpro.tsv &gt; go.annot InterProScan对于 InterProScan 可以本地化，也可以用 interProScan5.pl 将序列发送到官方服务器进行注释，资源允许，还是推荐本地化，网络版感觉还是有点慢～一个本地化教程: InterProScan的使用教程 http://www.bioinfo-scrounger.com/archives/164 eggNOG-Mapper （包括网页版和本地化）网页版关于这个注释方法网页版的推荐自己去摸索吧（就是和NCBI提交类似）=&gt; http://eggnogdb.embl.de/#/app/emapper 本地化推荐两个教程吧：序列功能注释神器：eggNOG-mapper，KEGG/COG/KOG/GO/BiGG 一网打尽 ： 序列功能注释神器：eggNOG-mapper，KEGG/COG/KOG/GO/BiGG 一网打尽 « Biostack.org =&gt; http://www.biostack.org/?p=698 应该是最好的eggnog-mapper功能注释教程：应该是最好的eggnog-mapper功能注释教程 - 简书（生信媛）=&gt; https://www.jianshu.com/p/e646c0fa6443 个人思考: 对于准确性的个人思考，基于比对，也就是基因相似性的注释方法(blastp,diamond)可能会取决于数据库的大小，因为在omicsbox中有涉及到相似度cut这一步，如果数据库不够大，那么相似度有的可能只为50(在cut值之上)，所以只使用Swiss-Prot等小数据库注释时可能需要提高cut值. eggnog的注释，存在两种模式diamond和hummer，前者官方推荐为存在接近物种，也就是在直系同源注释中有更好的表现，hummer则反之. 同样的，只要是比对，就会有cut相似度这一说，数据库的大小及深度(涉及的物种)，就会影响结果。其一个特点在于直系同源注释。这点omicsbox中出了filter with Taxid 来补充。 我个人觉得目前还是blast+interpro的准确性会更高一些，当然如果eggnog持续开发,扩大其数据库，以及支持整合diamond和hummer的结果将会成为新的宠儿。 参考资料 http://blog.sina.com.cn/s/blog_16152d7d70102xnc3.html https://github.com/bbuchfink/diamond http://www.jinciwei.cn/a342744.html https://github.com/bbuchfink/diamond/issues/79 https://github.com/bbuchfink/diamond/issues/159 https://github.com/bbuchfink/diamond/issues/165 http://www.biostack.org/?p=698 https://www.jianshu.com/p/e646c0fa6443 NGS 生物信息学分析 V6.0 陈连福 郑越","link":"/2019/09/16/GO-annotation/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2019/09/16/hello-world/"},{"title":"一个高杂合真菌基因组组装脚本","text":"categories: - assemble 前言及背景什么是基因组de novo测序？其是对某一物种进行高通量测序，利用高性能计算平台和生物信息学方法，在不依赖于参考基因组的情况下进行组装，从而绘制该物种的全基因组序列图谱。 针对基因组的特性，基因组常被分为两类：普通（简单）基因组和复杂基因组。简单基因组指单倍体，纯合二倍体或者杂合度&lt;0.5%，且重复序列含量&lt;50%，GC含量为35%到65%之间的二倍体。复杂基因组则指杂合率＞0.5%，重复序列含量＞50%，GC含量处于异常的范围（GC含量＜35%或者GC含量＞＝65%的二倍体，多倍体。诺禾致源对二倍体复杂基因组进一步细分为微杂合基因组（0.5%＜杂合率＜＝0.8%、高杂合基因组（杂合率＞0.8%）以及高重复基因组（重复序列比例&gt;50%）。复杂基因组的组装一直以来都是一个让科研工作者为之头疼的问题。科研工作者也为解决这个问题一直努力着。随着三代测序平台的更迭，测序subreads的长度不断的增长，以及光学图谱技术的出现（Hic,10xGenomic等）。重复序列导致的组装困难逐步被缓解。但高杂合这一特性任一直困扰着科研工作者。 为了解决杂合组装，各式各样的方案不断被提出。总体思路有下：1.设计实验方案获取单倍体（例如种间杂种；案例：Sequencing a Juglans regia × J. microcarpa hybrid yields high-quality genome assemblies of parental species）；2.设计适合于杂合基因组组装的软件，优化组装的算法；3.组装之后，再用去杂合软件去除杂合序列。 第一个思路很清晰，获取单倍体再测序，就解决了高杂合这个难点，可有时单倍体的获取真不是一般的难，局限性很大。 基于第二个思路，已有很多软件开发。有NOVOheter, Plantanus, MSR-CA，Plantanus-allee（Plantanus的升级版，支持Hic，10xGenomics等数据）等。此外还有一些软件有支持高杂合组装的模块，如Canu，SPAdes, Falon等。但实测的经验来看，效果都不是很好。 第三种思路的核心就是，居于相似性cut，目前接触过的的有Redundans，Haplomerger2，Purge_haplogs。Purge_haplogs除了考虑相似性，还有一大特性，就是通过分析比对read的覆盖度决定谁去谁留。此外，Haplomerger2和Purge_haplogs还支持重复序列部分的屏蔽。 今年我接手到了一个基因组大小为86M,杂合率约2.4%，重复序列率约为20%左右的真菌。测序策略为pacbio seq I + PE 150 。 本来打算再做一个Hic，但咨询一些测序公司之后，均表示真菌没有太多成功经验，且投入与产出可能不对等。故打消测Hic的念头。 基于已有的数据，我先采取了canu 单倍型组装、canu(多倍体模式，”batOptions=-dg 3 -db 3 -dr 1 -ca 500 -cp 50”组装，MECAT2，MaSuRCA、Falon、flye、wtdbg2 等组装软件进行了组装。接着使用 Purge_haplogs 、Redundans和Haplomerger2进行去杂合，然后再使用 FinisherSC进行基因组升级，最后使用nextpolish 进行 polish。经过测试，canu，MECAT2（经过nextpolish 进行 polish之后）， MaSuRCA的三个软件的表现相对较好。 去杂软件Purge_haplogs的适用性优于Redundans和Haplomerger2，去杂前后BUSCO评估基本不变。由于涉及到文章。故暂时只能提供最优的脚本。 组装案例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144# 测序数据 Bam to Fastq or Fastasamtools fastq -0 012m.subreads.fq -@ 32 subreads.bam# Assessment of genome size and heterozygosity(raw PE reads)mkdir genomescopecd genomescopeln -s ../012m_L1_?.fq ./jellyfish count -C -m 21 -s 1000000000 -t 32 *.fq -o reads.jfjellyfish histo -t 32 reads.jf &gt; reads.histoRscript /opt/biosoft/genomescope/genomescope.R reads.histo 21 150 output# 二代数据质控mkdir Trimmomaticcd Trimmomaticjava -jar /opt/biosoft/Trimmomatic-0.36/trimmomatic-0.36.jar PE -threads 32 -phred33 ../012m_L1_1.fq ../012m_L1_2.fq 012m_Trimmomatic.1.fq 012m_Trimmomatic.unpaired.1.fq 012m_Trimmomatic.2.fq 012m_Trimmomatic.unpaired.2.fq \\ILLUMINACLIP:/opt/biosoft/Trimmomatic-0.36/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:75 TOPHRED33cd ../# correct Illumina reads | Assessment of genome size and heterozygositymkdir Finderrorssource ~/.bash.pacbioErrorCorrectReads.pl PHRED_ENCODING=33 READS_OUT=012m FILL_FRAGMENTS=0 KEEP_KMER_SPECTRA=1 PAIRED_READS_A_IN=../fastuniq/012m.fastuniq.1.fastq PAIRED_READS_B_IN=../fastuniq/012m.fastuniq.1.fastq PLOIDY=2 PAIRED_SEP=251 PAIRED_STDEV=48# ErrorCorrectReads.pl也可以对基因组特性进行评估，但针对我的菌株来说，同已发布的邻近菌株比较，GenomeScope的结果要准确一些。# kmer plotcd 012m.fastq.kspecperl -p -i -e 's/\\@fns = \\(\\\"frag_reads_filt.25mer.kspec\\\", \\\"frag_reads_edit.24mer.kspec\\\", \\\"frag_reads_corr.25mer.kspec\\\"\\);\\n//' /opt/biosoft/ALLPATHS-LG/bin/KmerSpectrumPlot.plKmerSpectrumPlot.pl SPECTRA=1 FREQ_MAX=255perl -p -i -e 's/\\@fns = \\(\\\"frag_reads_filt.25mer.kspec\\\", \\\"frag_reads_edit.24mer.kspec\\\", \\\"frag_reads_corr.25mer.kspec\\\"\\);\\n//' /opt/biosoft/ALLPATHS-LG/bin/KmerSpectrumPlot.plconvert kmer_spectrum.cumulative_frac.log.lin.eps kmer_spectrum.cumulative_frac.log.lin.pngconvert kmer_spectrum.distinct.lin.lin.eps kmer_spectrum.distinct.lin.lin.pngconvert kmer_spectrum.distinct.log.log.eps kmer_spectrum.distinct.log.log.pngcd ../# Using LoRDEC to modify PacBio Readsmkdir LoRDECcd LoRDEClordec-correct -2 ../Finderrors/012m.paired.A.fastq ../Finderrors/012m.paired.B.fastq -i ../012m.subreads.fq -k 19 -o pacbio.LoRDEC.corrected.fasta -s 3 -T 32 &amp;&gt; lordec-correct.logseqkit seq -u pacbio.LoRDEC.corrected.fasta &gt; pacbio.corrected.fastacd ../############# Genome assembly ###############mkdir MaSuRCAcd MaSuRCAecho '# example configuration file DATA# Illumina paired end reads supplied as &lt;two-character prefix&gt; &lt;fragment mean&gt; &lt;fragment stdev&gt; &lt;forward_reads&gt; &lt;reverse_reads&gt;# if single-end, do not specify &lt;reverse_reads&gt;# MUST HAVE Illumina paired end reads to use MaSuRCAPE= pe 251 48 /home/bioinfo/data/012m/012m_L1_1.fq /home/bioinfo/data/012m/012m_L1_2.fq# Illumina mate pair reads supplied as &lt;two-character prefix&gt; &lt;fragment mean&gt; &lt;fragment stdev&gt; &lt;forward_reads&gt; &lt;reverse_reads&gt;# JUMP= sh 3600 200 /FULL_PATH/short_1.fastq /FULL_PATH/short_2.fastq# pacbio OR nanopore reads must be in a single fasta or fastq file with absolute path, can be gzipped# if you have both types of reads supply them both as NANOPORE typePACBIO=/home/bioinfo/data/012m/LoRDEC/pacbio.corrected.fasta# NANOPORE=/FULL_PATH/nanopore.fa# Other reads (Sanger, 454, etc) one frg file, concatenate your frg files into one if you have many# OTHER=/FULL_PATH/file.frg# synteny-assisted assembly, concatenate all reference genomes into one reference.fa; works for Illumina-only data# REFERENCE=/FULL_PATH/nanopore.faENDPARAMETERS# PLEASE READ all comments to essential parameters below, and set the parameters according to your project# set this to 1 if your Illumina jumping library reads are shorter than 100bpEXTEND_JUMP_READS=0# this is k-mer size for deBruijn graph values between 25 and 127 are supported, auto will compute the optimal size based on the read data and GC contentGRAPH_KMER_SIZE = auto# set this to 1 for all Illumina-only assemblies# set this to 0 if you have more than 15x coverage by long reads (Pacbio or Nanopore) or any other long reads/mate pairs (Illumina MP, Sanger, 454, etc)USE_LINKING_MATES = 0# specifies whether to run the assembly on the gridUSE_GRID=0# specifies grid engine to use SGE or SLURMGRID_ENGINE=SGE# specifies queue (for SGE) or partition (for SLURM) to use when running on the grid MANDATORYGRID_QUEUE=all.q# batch size in the amount of long read sequence for each batch on the gridGRID_BATCH_SIZE=500000000# use at most this much coverage by the longest Pacbio or Nanopore reads, discard the rest of the reads# can increase this to 30 or 35 if your reads are short (N50&lt;7000bp)LHE_COVERAGE=25# set to 0 (default) to do two passes of mega-reads for slower, but higher quality assembly, otherwise set to 1MEGA_READS_ONE_PASS=0# this parameter is useful if you have too many Illumina jumping library mates. Typically set it to 60 for bacteria and 300 for the other organisms # LIMIT_JUMP_COVERAGE = 300# these are the additional parameters to Celera Assembler. do not worry about performance, number or processors or batch sizes -- these are computed automatically. # CABOG ASSEMBLY ONLY: set cgwErrorRate=0.25 for bacteria and 0.1&lt;=cgwErrorRate&lt;=0.15 for other organisms.CA_PARAMETERS = cgwErrorRate=0.15# CABOG ASSEMBLY ONLY: whether to attempt to close gaps in scaffolds with Illumina or long read dataCLOSE_GAPS=1# auto-detected number of cpus to use, set this to the number of CPUs/threads per node you will be usingNUM_THREADS = 32# this is mandatory jellyfish hash size -- a safe value is estimated_genome_size*20JF_SIZE = 1740000000# ILLUMINA ONLY. Set this to 1 to use SOAPdenovo contigging/scaffolding module. Assembly will be worse but will run faster. Useful for very large (&gt;=8Gbp) genomes from Illumina-only dataSOAP_ASSEMBLY=0#Hybrid Illumina paired end + Nanopore/PacBio assembly ONLY. Set this to 1 to use Flye assembler for final assembly of corrected mega-reads. A lot faster than CABOG, at the expense of some contiguity. Works well even when MEGA_READS_ONE_PASS is set to 1. DO NOT use if you have less than 15x coverage by long reads.FLYE_ASSEMBLY=0END ' &gt; config.txt/opt/biosoft/MaSuRCA-3.3.4/bin/masurca config.txt./assemble.shmkdir purge_haplogscd purge_haplogsminimap2 -t 32 -ax map-pb ../final.genome.scf.fasta\\/home/bioinfo/data/012m/canu/012m.correctedReads.fasta.gz | samtools view -hF 256 - | samtools sort -@ 32 -m 2G -o aligned.bampurge_haplotigs hist -b aligned.bam -g ../final.genome.scf.fasta -t 20purge_haplotigs contigcov -i aligned.bam.gencov -o coverage_stats.csv -l 18 -m 76 -h 134purge_haplotigs purge -g ../final.genome.scf.fasta -c coverage_stats.csv -b aligned.bam -t 4 -a 50mkdir finisherSCcd finisherSCln -s ../curated.fasta ./contigs.fastaln -s ~/data/012m/canu/012m.correctedReads.fasta ./raw_reads.fastapython /opt/biosoft/finishingTool/finisherSC.py ./ /opt/biosoft/mummer4/bin/mkdir NextPolishcd NextPolishls ~/data/012m/Finderrors/012m.paired.?.fastq &gt; sgs.fofnecho '/home/bioinfo/data/012m/canu/012m.correctedReads.fasta' &gt; lgs.fofnecho '[General]job_type = localjob_prefix = nextPolishtask = defaultrewrite = yesrerun = 10parallel_jobs = 5multithread_jobs = 6genome = ../improved3.fastagenome_size = autoworkdir = ./01_rundirpolish_options = -p {multithread_jobs}[sgs_option]sgs_fofn = ./sgs.fofnsgs_options = -max_depth 100 -bwa[lgs_option]lgs_fofn = ./lgs.fofnlgs_options = -min_read_len 10k -max_read_len 150k -max_depth 60lgs_minimap2_options = -x map-pb[polish_options]-ploidy 2 ' &gt; run.cfg/opt/biosoft/NextPolish/nextPolish run.cfgcat ./01_rundir/01.kmer_count/*polish.ref.sh.work/polish_genome*/genome.nextpolish.part*.fasta &gt; genome.nextpolish.fasta 参考动植物基因组de novo常见问题杂基因组测序技术研究进展NextPolishSequencing a Juglans regia × J. microcarpa hybrid yields high-quality genome assemblies of parental speciesLoRDEC 利用二代数据纠错PacBio 数据genomescopeMaSuRCApurge_haplogs","link":"/2019/10/30/复杂基因组组装/"}],"tags":[],"categories":[]}